{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain Machine Learning Models\n",
    "\n",
    "\n",
    "### Outline\n",
    "\n",
    "* [Understanding model predictions with SHAP](#SHAP)\n",
    "* [Understanding model predictions with LIME](#LIME)\n",
    "* [Understanding models with TED](#TED)\n",
    "\n",
    "\n",
    "<img src=\"http://aix360.mybluemix.net/static/images/methods-choice.gif\" alt=\"Tree\" style=\"width: 1000px;\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy --upgrade\n",
    "!pip install aif360\n",
    "!pip install aix360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import os\n",
    "#import requests\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#import sklearn.datasets\n",
    "#import sklearn.ensemble\n",
    "from sklearn import svm     \n",
    "import time\n",
    "#np.random.seed(1)\n",
    "\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.datasets.lime_encoder import LimeEncoder\n",
    "from aif360.datasets import GermanDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "#from aix360.algorithms.protodash import ProtodashExplainer\n",
    "from aix360.algorithms.ted.TED_Cartesian import TED_CartesianExplainer\n",
    "from aix360.algorithms.shap import KernelExplainer\n",
    "#from aix360.datasets.cdc_dataset import CDCDataset\n",
    "from aix360.datasets.ted_dataset import TEDDataset\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "import shap\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"SHAP\"></a>\n",
    "# Understanding model predictions with SHAP\n",
    "\n",
    "[SHAP](https://github.com/slundberg/shap)\n",
    "\n",
    "<a class=\"anchor\" id=\"explain-single-shap\"></a>\n",
    "## Explain a single prediction\n",
    "\n",
    "A simple example with a K nearest neighbors ([knn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)) classification of the IRIS dataset based on the [original SHAP tutorial](https://slundberg.github.io/shap/notebooks/Iris%20classification%20with%20scikit-learn.html).\n",
    "\n",
    "Learn more about SHAP in [this chapter](https://christophm.github.io/interpretable-ml-book/shap.html#shap-summary-plot) in the Interpretable Machine Learning by Christoph Molnar.\n",
    "\n",
    "The goal of SHAP is to explain the prediction of an instance x by computing the contribution of each feature to the prediction. Features with large absolute Shapley values are important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.datasets.iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(*shap.datasets.iris(), test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(f):\n",
    "    print(\"Accuracy = {0}%\".format(100*np.sum(f(X_test) == Y_test)/len(Y_test)))\n",
    "    time.sleep(0.5) # to let the print get out before any progress bars\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "n_neighbors = 5   # default=5\n",
    "weights='uniform'  # 'uniform' or 'distance'\n",
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "print_accuracy(knn.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability estimates\n",
    "knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapexplainer = KernelExplainer(knn.predict_proba, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aix360 style for explaining input instances\n",
    "shap_values = shapexplainer.explain_instance(X_test.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The individual force plot\n",
    "\n",
    "Red/blue: Features that push the prediction higher (to the right) are shown in red, and those pushing the prediction lower are in blue.\n",
    "\n",
    "The plot is centered on the x-axis at explainer.expected_value. All SHAP values are relative to the model's expected value like a linear model's effects are relative to the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapexplainer.explainer.expected_value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shapexplainer.explainer.expected_value[0], shap_values[0], X_test.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[23,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shapexplainer.explain_instance(X_test.iloc[23,:])\n",
    "shap.force_plot(shapexplainer.explainer.expected_value[0], shap_values[0], X_test.iloc[23,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"explain-all-shap\"></a>\n",
    "## Explain all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_all = shapexplainer.explain_instance(X_test)\n",
    "shap_values_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_all, X_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aix360 style for explaining input instances\n",
    "shap_values = shapexplainer.explain_instance(X_test)\n",
    "shap.force_plot(shapexplainer.explainer.expected_value[0], shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"LIME\"></a>\n",
    "# Understanding model predictions with LIME\n",
    "\n",
    "Local Interpretable Model-Agnostic Explanations\n",
    "\n",
    "[LIME](https://lime-ml.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aif360_location = !python -c \"from distutils.sysconfig import get_python_lib; print(get_python_lib())\"\n",
    "import os\n",
    "install_loc = os.path.join(aif360_location[0], \"aif360/data/raw/german/\")\n",
    "%cd $install_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget ftp://ftp.ics.uci.edu/pub/machine-learning-databases/statlog/german/german.data\n",
    "!wget ftp://ftp.ics.uci.edu/pub/machine-learning-databases/statlog/german/german.doc\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_german = GermanDataset(protected_attribute_names=['age'],\n",
    "                    privileged_classes=[lambda x: x >= 25],      \n",
    "                    features_to_drop=['personal_status', 'sex']) \n",
    "\n",
    "dataset_german_train, dataset_german_test = dataset_german.split([0.7], shuffle=True)\n",
    "\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "scale_german = StandardScaler().fit(dataset_german_train.features)\n",
    "\n",
    "X_train = scale_german.transform(dataset_german_train.features)\n",
    "y_train = dataset_german_train.labels.ravel()\n",
    "w_train = dataset_german_train.instance_weights.ravel()\n",
    "\n",
    "X_test = scale_german.transform(dataset_german_test.features)\n",
    "y_test = dataset_german_test.labels.ravel()\n",
    "w_test = dataset_german_test.instance_weights.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reweigh the data\n",
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "               privileged_groups=privileged_groups)\n",
    "\n",
    "# compute the weights for reweighing the dataset\n",
    "RW.fit(dataset_german_train)\n",
    "\n",
    "# transform the dataset to a new dataset based on the estimated transformation\n",
    "dataset_transf_train = RW.transform(dataset_german_train)\n",
    "dataset_transf_test = RW.transform(dataset_german_test)\n",
    "\n",
    "scale_transf = StandardScaler().fit(dataset_transf_train.features)\n",
    "\n",
    "X_train_transf = scale_transf.transform(dataset_transf_train.features)\n",
    "y_train_transf = dataset_transf_train.labels.ravel()\n",
    "w_train_transf = dataset_transf_train.instance_weights.ravel()\n",
    "\n",
    "X_test_transf = scale_transf.transform(dataset_transf_test.features)\n",
    "y_test_transf = dataset_transf_test.labels.ravel()\n",
    "w_test_transf = dataset_transf_test.instance_weights.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_german_train = BinaryLabelDatasetMetric(dataset_german_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "display(Markdown(\"#### BIAS METRICS\"))\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"mean_difference = %f\" % metric_german_train.mean_difference())\n",
    "print(\"disparate_impact = %f\" % metric_german_train.disparate_impact())\n",
    "\n",
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                         unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)\n",
    "\n",
    "display(Markdown(\"#### Reweighted training dataset\"))\n",
    "print(\"mean_difference = %f\" % metric_transf_train.mean_difference())\n",
    "print(\"disparate_impact = %f\" % metric_transf_train.disparate_impact())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmod_transf = LogisticRegression()\n",
    "\n",
    "# train the model\n",
    "lmod_transf.fit(X_train_transf, y_train_transf, \n",
    "         sample_weight=dataset_transf_train.instance_weights)\n",
    "\n",
    "# calculate predicted labels\n",
    "y_train_pred_transf = lmod_transf.predict(X_train_transf)\n",
    "\n",
    "# assign positive class index\n",
    "pos_ind_transf = np.where(lmod_transf.classes_ == dataset_transf_train.favorable_label)[0][0]\n",
    "\n",
    "# add predicted labels to predictions dataset\n",
    "dataset_transf_train_pred = dataset_transf_train.copy()\n",
    "dataset_transf_train_pred.labels = y_train_pred_transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limeData = LimeEncoder().fit(dataset_german_train)\n",
    "s_train = limeData.transform(dataset_german_train.features)\n",
    "s_test = limeData.transform(dataset_german_test.features)\n",
    "\n",
    "scale = scale_transf\n",
    "model = lmod_transf   \n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(s_train ,class_names=limeData.s_class_names, \n",
    "                                                   feature_names = limeData.s_feature_names,\n",
    "                                                   categorical_features=limeData.s_categorical_features, \n",
    "                                                   categorical_names=limeData.s_categorical_names, \n",
    "                                                   kernel_width=3, verbose=False,discretize_continuous=True)\n",
    "\n",
    "s_predict_fn = lambda x: model.predict_proba(scale.transform(limeData.inverse_transform(x)))\n",
    "\n",
    "display(Markdown(\"#### Reweighted training dataset\"))\n",
    "\n",
    "i1 = 0\n",
    "exp = explainer.explain_instance(s_test[i1], s_predict_fn, num_features=8)\n",
    "exp.show_in_notebook(show_all=False)\n",
    "print(\"        Actual label: \" + str(dataset_german_test.labels[i1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = 1\n",
    "exp = explainer.explain_instance(s_test[i1], s_predict_fn, num_features=8)\n",
    "exp.show_in_notebook(show_all=False)\n",
    "print(\"        Actual label: \" + str(dataset_german_test.labels[i1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2 = 23\n",
    "exp = explainer.explain_instance(s_test[i2], s_predict_fn, num_features=8)\n",
    "exp.show_in_notebook(show_all=False)\n",
    "print(\"        Actual label: \" + str(dataset_german_test.labels[i2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"TED\"></a>\n",
    "# Understanding models with TED\n",
    "\n",
    "Most suited for use cases where matching explanations to the mental model of the explanation consumer is the highest priority; i.e., where the explanations are similar to what would be produced by a domain expert.\n",
    "\n",
    "The **TED_CartesianExplainer** is an implementation of the algorithm in the AIES'19 paper by [Hind et al.](), that takes the Cartesian product of the label and explanation and creates a new label (YE) and uses this to train a (multiclass) classifier. \n",
    "\n",
    "This approach can use any classifier (passed as a parameter), as long as it complies with the fit/predict paradigm.\n",
    "\n",
    "## Synthetic dataset\n",
    "\n",
    "A synthetically generated [dataset](https://github.com/IBM/AIX360/blob/master/aix360/data/ted_data/Retention.csv) is used generated with this [code](https://github.com/IBM/AIX360/blob/master/aix360/data/ted_data/GenerateData.py) as part of aix360.\n",
    "\n",
    "### Assigning labels\n",
    "\n",
    "25 rules are created, for why a retention action is needed to reduce the chances of an employee choosing to leave a fictitious company. These rules are motivated by common scenarios, such as not getting a promotion in a while, not being paid competitively, receiving a disappointing evaluation, being a new employee in certain organizations with inherently high attrition, not having a salary that is consistent with positive evaluations, mid-career crisis, etc.   \n",
    "\n",
    "Each of these 25 rules would result in the label \"Yes\"; i.e., the employee is a risk to leave the company. Because the rules capture the reason for the \"Yes\", we use the rule number as the explanation (E), which is required by the TED framework.\n",
    "\n",
    "If none of the rules are satisfied, it means the employee is not a candidate for a retention action; i.e., a \"No\" label is assigned.  \n",
    "\n",
    "### Dataset characteristics\n",
    "\n",
    "10,000 fictious employees (X) are generated and the 26 (25 Yes + 1 No) rules are applied to produce Yes/No labels (Y), using these rules as explanations (E).  After applying these rules, the resulting dataset has the following characteristics:\n",
    "- Yes (33.8%)\n",
    "- No (66.2%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose the dataset into X, Y, E     \n",
    "X, Y, E = TEDDataset().load_file('Retention.csv')\n",
    "print(\"X's shape:\", X.shape)\n",
    "print(\"Y's shape:\", Y.shape)\n",
    "print(\"E's shape:\", E.shape)\n",
    "print()\n",
    "\n",
    "# set up train/test split\n",
    "X_train, X_test, Y_train, Y_test, E_train, E_test = train_test_split(X, Y, E, test_size=0.20, random_state=0)\n",
    "print(\"X_train shape:\", X_train.shape, \", X_test shape:\", X_test.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape, \", Y_test shape:\", Y_test.shape)\n",
    "print(\"E_train shape:\", E_train.shape, \", E_test shape:\", E_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifier and pass to TED_CartesianExplainer\n",
    "estimator = svm.SVC(kernel='linear')\n",
    "# estimator = DecisionTreeClassifier()\n",
    "# estimator = RandomForestClassifier()\n",
    "# estimator = AdaBoostClassifier()\n",
    "\n",
    "ted = TED_CartesianExplainer(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training the classifier\")\n",
    "\n",
    "ted.fit(X_train, Y_train, E_train)   # train classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ted1\"></a>\n",
    "## Explain a single prediction\n",
    "\n",
    "The trained TED classifier is now ready for predictions with explanations.   We construct some raw feature vectors, created from the original dataset, and ask for a label (Y) prediction and its explanation (E)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance level example \n",
    "X1 = [[1, 2, -11, -3, -2, -2,  22, 22]]\n",
    "\n",
    "# correct answers:  Y:-10; E:13\n",
    "Y1, E1 = ted.predict_explain(X1)\n",
    "print(\"Predicting for feature vector:\")\n",
    "print(\" \", X1[0])\n",
    "print(\"\\t\\t      Predicted \\tCorrect\")\n",
    "print(\"Label(Y)\\t\\t \" + np.array2string(Y1[0]) + \"\\t\\t   -10\")\n",
    "print(\"Explanation (E) \\t \" + np.array2string(E1[0]) + \"\\t\\t   13\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = [[3, 1, -11, -2, -2, -2, 296, 0]]\n",
    "\n",
    "## correct answers: Y:-11, E:25\n",
    "Y2, E2 = ted.predict_explain(X2)\n",
    "print(\"Predicting for feature vector:\")\n",
    "print(\" \", X2[0])\n",
    "\n",
    "print(\"\\t\\t      Predicted \\tCorrect\")\n",
    "print(\"Label(Y)\\t\\t \" + np.array2string(Y2[0]) + \"\\t\\t   -11\")\n",
    "print(\"Explanation (E) \\t \" + np.array2string(E2[0]) + \"\\t\\t   25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a more relevant human interface\n",
    "\n",
    "TED_CaresianExplainer can produce the correct explanation for a feature vector, but simply producing \"3\" as an explanation is not sufficient in most uses. This section shows one way to implement the mapping of real explanations to the explanation IDs that TED requires. This is inspired by the [FICO reason codes](https://www.fico.com/en/latest-thinking/product-sheet/us-fico-score-reason-codes), which are explanations for a FICO credit score.  \n",
    "\n",
    "In this case the explanations are text, but the same idea can be used to map explanation IDs to other formats, such as a file name containing an audio or video explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label_Strings =[\"IS\", \"Approved for\"]\n",
    "def labelToString(label) :\n",
    "    if label == -10 :\n",
    "        return \"IS\"\n",
    "    else :\n",
    "        return \"IS NOT\"\n",
    "\n",
    "Explanation_Strings = [\n",
    "    \"Seeking Higher Salary in Org 1\",\n",
    "    \"Promotion Lag, Org 1, Position 1\",\n",
    "    \"Promotion Lag, Org 1, Position 2\",\n",
    "    \"Promotion Lag, Org 1, Position 3\",\n",
    "    \"Promotion Lag, Org 2, Position 1\",\n",
    "    \"Promotion Lag, Org 2, Position 2\",\n",
    "    \"Promotion Lag, Org 2, Position 3\",\n",
    "    \"Promotion Lag, Org 3, Position 1\",\n",
    "    \"Promotion Lag, Org 3, Position 2\",\n",
    "    \"Promotion Lag, Org 3, Position 3\",\n",
    "    \"New employee, Org 1, Position 1\",\n",
    "    \"New employee, Org 1, Position 2\",\n",
    "    \"New employee, Org 1, Position 3\",\n",
    "    \"New employee, Org 2, Position 1\",\n",
    "    \"New employee, Org 2, Position 2\",\n",
    "    \"Disappointing evaluation, Org 1\",\n",
    "    \"Disappointing evaluation, Org 2\",\n",
    "    \"Compensation does not match evaluations, Med rating\",\n",
    "    \"Compensation does not match evaluations, High rating\",\n",
    "    \"Compensation does not match evaluations, Org 1, Med rating\",\n",
    "    \"Compensation does not match evaluations, Org 2, Med rating\",\n",
    "    \"Compensation does not match evaluations, Org 1, High rating\",\n",
    "    \"Compensation does not match evaluations, Org 2, High rating\",\n",
    "    \"Mid-career crisis, Org 1\",\n",
    "    \"Mid-career crisis, Org 2\",\n",
    "    \"Did not match any retention risk rules\"]\n",
    "\n",
    "\n",
    "print(\"Employee #1 \" + labelToString(Y1[0]) + \" a retention risk with explanation: \" + Explanation_Strings[E1[0]])\n",
    "print()\n",
    "print(\"Employee #2 \" + labelToString(Y2[0]) + \" a retention risk with explanation: \" + Explanation_Strings[E2[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ted2\"></a>\n",
    "## Overall model accuracy\n",
    "\n",
    "How well does TED_Cartesian do in predicting all test labels (Y) and explanations (E)?\n",
    "\n",
    "The \"score\" method of TED_Cartesian calculates this. The accuracy of predicting the combined YE labels could be of interest to researchers who want to better understand the inner workings of TED_Cartesian.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YE_accuracy, Y_accuracy, E_accuracy = ted.score(X_test, Y_test, E_test)    # evaluate the classifier\n",
    "print(\"Evaluating accuracy of TED-enhanced classifier on test data\")\n",
    "print(' Accuracy of predicting Y labels: %.2f%%' % (100*Y_accuracy))\n",
    "print(' Accuracy of predicting explanations: %.2f%%' % (100*E_accuracy))\n",
    "print(' Accuracy of predicting Y + explanations: %.2f%%' % (100*YE_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is easy to use the TED_CartesianExplainer if you have a training dataset that contains explanations. The framework is general in that it can use any classification technique that follows the fit/predict paradigm, so that if you already have a favorite algorithm, you can use it with the TED framework.\n",
    "* The main advantage of this algorithm is that the quality of the explanations produced are exactly the same quality as those that the algorithm is trained on.  Thus, if you teach (train) the system well with good training data and good explanations, you will get good explanations out in a language you should understand.\n",
    "* The downside of this approach is that someone needs to create explanations. This should be straightforward when a domain expert is creating the initial training data: if they decide a loan should be rejected, they should know why, and if they do not, it may not be a good decision.\n",
    "* However, this may be more of a challenge when a training dataset already exists without explanations and now someone needs to create the explanations.  The original person who did the labeling of decisions may no longer be available, so the explanations for the decisions may not be known.  In this case, we argue, the system is in a dangerous state.  Training data exists that no one understands why it is labeled in a certain way.   Asking the model to explain one of its predictions when no person can explain an instance in the training data does not seem consistent.\n",
    "* Dealing with this situation is one of the open research problems that comes from the TED approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
